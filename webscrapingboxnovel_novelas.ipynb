{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from webdriver_manager.firefox import GeckoDriverManager\n",
    "from selenium.webdriver.firefox.service import Service as FirefoxService\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import translators as ts\n",
    "import undetected_chromedriver as uc\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import time\n",
    "from pymongo import MongoClient\n",
    "from datetime import datetime\n",
    "import csv\n",
    "from google_trans_new import google_translator\n",
    "from langdetect import detect, DetectorFactory\n",
    "DetectorFactory.seed = 0 \n",
    "from collections import Counter\n",
    "from bson.objectid import ObjectId\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_apis = ['bing', 'google', 'baidu', 'yandex', 'alibaba', 'apertium', \n",
    "           'argos', 'caiyun', 'cloudTranslation', 'deepl', 'elia', \n",
    "           'hujiang', 'iciba', 'iflytek', 'iflyrec', 'itranslate', \n",
    "           'judic', 'languageWire', 'lingvanex', 'mglip', 'mirai', \n",
    "           'modernMt', 'myMemory', 'niutrans', 'papago', 'qqFanyi', \n",
    "           'qqTranSmart', 'reverso', 'sogou', 'sysTran', 'tilde', \n",
    "           'translateCom', 'translateMe', 'utibet', 'volcEngine',\n",
    "           'yeekit', 'youdao',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient('mongodb://192.168.1.11:27017/')\n",
    "\n",
    "# Selecciona la base de datos\n",
    "db = client['recopilarnovelas']\n",
    "coleccion_app_novela = db['app_novela']\n",
    "coleccion_app_capitulo = db['app_capitulo']\n",
    "coleccion_app_contenidocapitulo = db['app_contenidocapitulo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def traducir(texto):\n",
    "    contenido_p = ''\n",
    "    for api in ts_apis:\n",
    "        try:\n",
    "            contenido_p = ts.translate_text(\n",
    "            texto, translator=api, to_language='es')\n",
    "            break\n",
    "        except Exception as e:\n",
    "            contenido_p = traducir(texto)\n",
    "            break\n",
    "    return contenido_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try:\n",
    "#     df_list_novels = pd.read_csv('chapters/boxnovel_novelas.csv', sep=';', quotechar='\"', quoting=csv.QUOTE_NONNUMERIC)\n",
    "# except:\n",
    "#     df_list_novels = pd.DataFrame(columns=['nombre', 'url'])\n",
    "# df_list_novels\n",
    "# df_list_novels = pd.DataFrame(columns=['nombre', 'url'])\n",
    "# df_existing_novels =pd.read_csv('existing_novels.csv', encoding='utf-8-sig', sep=';', quotechar='\"', quoting=csv.QUOTE_NONNUMERIC)\n",
    "# df_existing_novels\n",
    "df_list_novels = pd.DataFrame(columns=['nombre', 'url'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# options = webdriver.ChromeOptions()\n",
    "options = webdriver.FirefoxOptions()\n",
    "options.add_argument('--no-daemon')\n",
    "options.add_argument('--disable-blink-features=AutomationControlled')\n",
    "options.add_argument('--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://boxnovel.com/novel/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# driver = uc.Chrome(options=options, service = Service(executable_path=ChromeDriverManager().install()))\n",
    "# driver = webdriver.Firefox(options=options, service=FirefoxService(GeckoDriverManager().install()))\n",
    "driver = webdriver.Firefox(service=FirefoxService(GeckoDriverManager().install()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(url)\n",
    "time.sleep(5)\n",
    "# driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "By.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vsd https://bronovel.com/novels/vsd/\n",
      "vsdv https://bronovel.com/novels/vsdv/\n",
      "Swallowed Star https://bronovel.com/novels/swallowed-star/\n",
      "1[{\"variableName\": \"ID_TO_MEANING\", \"type\": \"dictionary\", \"supportedEngines\": [\"pandas\"], \"isLocalVariable\": true, \"rawType\": \"builtins.dict\"}, {\"variableName\": \"NULL\", \"type\": \"unknown\", \"supportedEngines\": [\"pandas\"], \"isLocalVariable\": true, \"rawType\": \"_pydevd_bundle.pydevd_constants.Null\"}]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if df_list_novels.empty:\n",
    "    list_novels = {\"nombre\":[],\"url\":[]}\n",
    "    idx = 2\n",
    "    while idx <=163:\n",
    "        try:\n",
    "            html = driver.page_source\n",
    "            soup = bs(html, 'html.parser')\n",
    "            page_listing_item = soup.find_all('div', class_='page-listing-item')\n",
    "            # print(page_listing_item)\n",
    "            for page_list in page_listing_item:\n",
    "                for item in page_list.find_all('div', class_='item-summary'):\n",
    "                    title = item.find('div', class_='post-title').find('a')\n",
    "                    title_text = ''.join([x for x in title.getText() if x.isalnum() or x == ' '])\n",
    "                    title_url = title.get('href')\n",
    "                    print(f\"{title_text} {title_url}\")\n",
    "                    list_novels['nombre'].append(title_text)\n",
    "                    list_novels['url'].append(title_url)\n",
    "            driver.get(f\"{url}/page/{idx}\")\n",
    "            # time.sleep(1)\n",
    "        except:\n",
    "            pass\n",
    "        idx+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list_novels = pd.DataFrame(list_novels)\n",
    "df_list_novels.to_csv(r'D:\\PycharmProjects\\novelasligeraswebscrapping\\chapters\\boxnovel_novelas.csv', index=False, encoding='utf-8', sep=';', quotechar='\"', quoting=csv.QUOTE_NONNUMERIC)\n",
    "df_list_novels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_novel_data(driver, novel_url):\n",
    "    # driver.get(novel_url)\n",
    "    # time.sleep(5)\n",
    "    html_novel = driver.page_source\n",
    "    soup_novel = bs(html_novel, 'html.parser')\n",
    "    title = soup_novel.find('div', class_='post-title').find('h1').getText().strip().rstrip()\n",
    "    title = ''.join([x for x in title if x.isalnum() or x == ' '])\n",
    "    tab_summary = soup_novel.find('div',class_='tab-summary')\n",
    "    post_content = tab_summary.find('div', class_='post-content').find_all('div', class_='post-content_item')\n",
    "    post_status = tab_summary.find('div', class_='post-status').find_all('div', class_='post-content_item')\n",
    "    author = ''\n",
    "    genre = ''\n",
    "    status = ''\n",
    "    for div_item in post_content:\n",
    "        cabecera_resumen = div_item.find('div', class_='summary-heading').find('h5').getText().strip().rstrip()\n",
    "        \n",
    "        if 'author' in cabecera_resumen.lower():\n",
    "            author = div_item.find('div', class_='summary-content').getText().strip().rstrip()\n",
    "        if 'genre' in cabecera_resumen.lower():\n",
    "            genre = div_item.find('div', class_='summary-content').getText().strip().rstrip()\n",
    "    for div_item in post_status:\n",
    "        cabecera_resumen = div_item.find('div', class_='summary-heading').find('h5').getText().strip().rstrip()\n",
    "        if 'status' in cabecera_resumen.lower():\n",
    "            status = div_item.find('div', class_='summary-content').getText().strip().rstrip()\n",
    "\n",
    "    try:\n",
    "        img_src = tab_summary.find('div', class_='summary_image').find('img').get('src')\n",
    "    except:\n",
    "        img_src = ''\n",
    "\n",
    "    try:\n",
    "        description = soup_novel.find('div', class_='description-summary').find('div', id='editdescription').getText().strip().rstrip()\n",
    "    except:\n",
    "        try:\n",
    "            description = soup_novel.find('div', class_='description-summary').find('div', class_='summary__content').getText().strip().rstrip()\n",
    "        except:\n",
    "            description = 'No Description.'\n",
    "\n",
    "    novel_data = {\n",
    "        \"sitio_id\": \"66b2b6f538c8afe8512e31aa\",\n",
    "        \"nombre\": title.upper(),\n",
    "        \"sinopsis\": description,\n",
    "        \"autor\": author,\n",
    "        \"genero\": genre,\n",
    "        \"status\": 'emision' if status == 'Ongoing' else 'completo',\n",
    "        \"url\": novel_url,\n",
    "        \"imagen_url\": img_src,\n",
    "        \"created_at\": datetime.now(),\n",
    "        \"updated_at\": datetime.now()\n",
    "    }\n",
    "    return novel_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chapter_data(driver, url_novel, novel_id, collection):\n",
    "    # driver.get(url_novel)\n",
    "    # time.sleep(5)\n",
    "    html_novel = driver.page_source\n",
    "    soup_novel = bs(html_novel, 'html.parser')\n",
    "    panel_chapter = soup_novel.find('div', class_='page-content-listing').find('ul', class_='main').find_all('li')\n",
    "    panel_chapter = panel_chapter[::-1]\n",
    "\n",
    "    existing_chapters = {str(x['nombre']).strip().rstrip():str(x['_id']) for x in collection.find({'novela_id': novel_id}, {'_id':1,'nombre': 1})}\n",
    "\n",
    "    for row in panel_chapter:\n",
    "        nombre_cap = row.find('a').getText().strip().rstrip()\n",
    "        chapter_url = row.find('a').get('href')\n",
    "        if nombre_cap not in existing_chapters.keys():\n",
    "            chapter_data = {\n",
    "                \"novela_id\": novel_id,\n",
    "                \"nombre\": nombre_cap,\n",
    "                \"url\": chapter_url,\n",
    "                \"created_at\": datetime.now(),\n",
    "                \"updated_at\": datetime.now()\n",
    "            }\n",
    "            collection.insert_one(chapter_data)\n",
    "            print(f'Url de {nombre_cap} ha sido insertada')\n",
    "        else:\n",
    "            resultado = collection.update_one(\n",
    "                {'_id': ObjectId(existing_chapters[nombre_cap])},\n",
    "                {'$set': {'url': chapter_url}}\n",
    "            )\n",
    "            print(f'Url de {nombre_cap} actualizada: {resultado.modified_count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# existing_novels =  [{'_id': str(x['_id']),'nombre': x['nombre'], 'url': x['url']} for x in coleccion_app_novela.find({}, {'_id': 1, 'nombre':1, 'url': 1})]\n",
    "# print(existing_novels[:5])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# for idx, novel in df_existing_novels.iterrows(): \n",
    "#     print(f\"{idx} {novel['_id']} {novel['nombre']} {novel['url']} ya existe, hay que actualizar la URL\")\n",
    "#     found_match = True\n",
    "#     resultado = coleccion_app_novela.update_one(\n",
    "#         {'_id': ObjectId(novel['_id'])},\n",
    "#         {'$set': {'url': novel['url']}}\n",
    "#     )\n",
    "#     print(f'Documentos actualizados: {resultado.modified_count}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "existing_novels =  [{'_id': str(x['_id']),'nombre': x['nombre'], 'url': x['url']} for x in coleccion_app_novela.find({'sitio_id':'66b2b6f538c8afe8512e31aa'}, {'_id': 1, 'nombre':1, 'url': 1})]\n",
    "existing_novels_names = {x['nombre']:x['_id'] for x in existing_novels}\n",
    "existing_novels_url = {x['url']:x['_id'] for x in existing_novels}\n",
    "for idx, novel in df_list_novels.iterrows():\n",
    "    # driver.get(novel['url'])\n",
    "    if str(novel['url']).strip().rstrip() in existing_novels_url.keys():\n",
    "        novel_id = existing_novels_url[str(novel['url']).strip().rstrip()]\n",
    "        print(f\"{idx} {novel_id} {str(novel['nombre']).upper().strip().rstrip()} {novel['url']} ya existe, hay que actualizar la URL\")\n",
    "        pass\n",
    "        driver.get(novel['url'])\n",
    "        time.sleep(5)\n",
    "        resultado = coleccion_app_novela.update_one(\n",
    "            {'_id': ObjectId(novel_id)},\n",
    "            {'$set': {'url': novel['url']}}\n",
    "        )\n",
    "        print(f'Documentos actualizados: {resultado.modified_count}')\n",
    "        try:\n",
    "            get_chapter_data(driver, novel['url'], novel_id, coleccion_app_capitulo)\n",
    "            print(f\"Todos los capítulos publicados de '{str(novel['nombre']).upper().strip().rstrip()}' han sido ingresados a la Base de Datos.\")\n",
    "        except Exception as e:\n",
    "            print('=======================================================================================================================')\n",
    "            print(f\"Error al procesar la novela '{novel['url']}': {e}\")\n",
    "            print('=======================================================================================================================')\n",
    "            pass\n",
    "    else:\n",
    "        print(f\"{idx} {str(novel['nombre']).upper().strip().rstrip()} {novel['url']} no existe, hay que crear la novela\")\n",
    "        driver.get(novel['url'])\n",
    "        time.sleep(5)\n",
    "        novel_data = get_novel_data(driver, novel['url'])\n",
    "        novel_id = str(coleccion_app_novela.insert_one(novel_data).inserted_id)\n",
    "        print(f\"Novela '{novel_data['nombre']}' ingresada a la Base de Datos.\")\n",
    "        try:\n",
    "            get_chapter_data(driver, novel['url'], novel_id, coleccion_app_capitulo)\n",
    "            print(f\"Todos los capítulos publicados de '{str(novel['nombre']).upper().strip().rstrip()}' han sido ingresados a la Base de Datos.\")\n",
    "        except Exception as e:\n",
    "            print('=======================================================================================================================')\n",
    "            print(f\"Error al procesar la novela {idx} ==> {novel['nombre']}: {e}\")\n",
    "            print('=======================================================================================================================')\n",
    "            pass\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coleccion_app_capitulo.delete_many({'novela_id': '666f9673d39ea517840211d4'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# existing_novels =  [{'_id': str(x['_id']),'nombre': x['nombre'], 'url': x['url']} for x in coleccion_app_novela.find({'sitio_id':'65e7e19f7963e189aa4c1258'}, {'_id': 1, 'nombre':1, 'url': 1})]\n",
    "# for novel in existing_novels:\n",
    "#     print(novel['_id'], end=' | ')\n",
    "#     coleccion_app_capitulo.delete_many({'novela_id': str(novel['_id'])})\n",
    "# coleccion_app_novela.delete_many({'sitio_id':'65e7e19f7963e189aa4c1258'})"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for novela in existing_novels:\n",
    "    print(f\"Iniciando actualizacion de capitulos de la Novela {novela['nombre']}!.\")\n",
    "    try:\n",
    "        get_chapter_data(driver, novela['url'], novela['_id'], coleccion_app_capitulo)\n",
    "        print(f\"Todos los capítulos publicados de '{novela['nombre']}' han sido ingresados a la Base de Datos.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error al procesar la novela '{novela['url']}': {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "existing_novels =  [{'_id': str(x['_id']),'nombre': x['nombre'], 'url': x['url']} for x in coleccion_app_novela.find({'sitio_id':'66b2b6f538c8afe8512e31aa'}, {'_id': 1, 'nombre':1, 'url': 1})]\n",
    "df_existing_novels = pd.DataFrame(existing_novels)\n",
    "df_existing_novels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_existing_novels.to_csv(r'D:\\PycharmProjects\\novelasligeraswebscrapping\\chapters\\existing_novels_boxnovel.csv', index=False, encoding='utf-8-sig', sep=';', quotechar='\"', quoting=csv.QUOTE_NONNUMERIC)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "urls = [doc['url'] for doc in coleccion_app_novela.find({}, {'url': 1, '_id': 0})]\n",
    "# Contar las repeticiones de cada URL\n",
    "contador_urls = Counter(urls)\n",
    "url_repetidos = [url for url, conteo in contador_urls.items() if conteo>1]\n",
    "print(url_repetidos)\n",
    "for x in url_repetidos:\n",
    "    print(x)\n",
    "    print(list(coleccion_app_novela.find({'url': x}, {'_id': 1}).sort('created_at', -1)))\n",
    "    id = list(coleccion_app_novela.find({'url': x}, {'_id': 1}).sort('created_at', -1))[0]['_id']\n",
    "    print(coleccion_app_capitulo.delete_many({'novela_id': id}))\n",
    "#     print('**********************************************************************************************')\n",
    "    print(coleccion_app_novela.delete_one({'_id': ObjectId(id)}))\n",
    "#     print('========================================================================')\n",
    "#     print('========================================================================')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# nombres = [doc['nombre'] for doc in coleccion_app_novela.find({}, {'nombre': 1, '_id': 0})]\n",
    "# # Contar las repeticiones de cada URL\n",
    "# contador_nombres = Counter(nombres)\n",
    "# nombres_repetidos = [nombre for nombre, conteo in contador_nombres.items() if conteo>1]\n",
    "# # print(nombres_repetidos)\n",
    "# for x in nombres_repetidos:\n",
    "#     print(x)\n",
    "# #     print(list(coleccion_app_novela.find({'nombre': x}, {'_id': 1}).sort('created_at', -1)))\n",
    "#     id = list(coleccion_app_novela.find({'nombre': x}, {'_id': 1}).sort('created_at', -1))[0]['_id']\n",
    "#     coleccion_app_capitulo.delete_many({'novela_id': id})\n",
    "#     print('**********************************************************************************************')\n",
    "#     coleccion_app_novela.delete_one({'_id': ObjectId(id)})\n",
    "#     print('========================================================================')\n",
    "#     print('========================================================================')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# coleccion_app_capitulo = db['app_capitulo']\n",
    "# capitulos_novelas_base = coleccion_app_capitulo.find()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# for capitulo in capitulos_novelas_base:\n",
    "#     if detect(capitulo['nombre']) == 'en':\n",
    "#         print(capitulo['_id'],detect(capitulo['nombre']),capitulo['nombre'])\n",
    "#         coleccion_app_capitulo.update_one({'_id': capitulo['_id']}, {\n",
    "#             '$set': {'nombre': traducir(capitulo['nombre'])}\n",
    "#         })\n",
    "#     # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enviar_contenido_capitulo(novel_id,capitulo_id,texto_capitulo):\n",
    "    url_contenido_capitulos = \"http://192.168.1.11:8000/api/contenidocapitulos/\"\n",
    "    headers = {\n",
    "        'Content-Type': 'application/json'\n",
    "    }\n",
    "    payload_chapter = {\n",
    "        \"novela_id\": novel_id,\n",
    "        \"capitulo_id\": capitulo_id,\n",
    "        \"texto\": texto_capitulo,\n",
    "        \"created_at\": datetime.now().isoformat(),\n",
    "        \"updated_at\": datetime.now().isoformat()\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        res_cap = requests.post(url_contenido_capitulos, headers=headers, json=payload_chapter)\n",
    "        res_cap.raise_for_status()\n",
    "        return res_cap.json()['_id']\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error al enviar el contenido del capítulo: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in df_existing_novels.iterrows():\n",
    "    # if row['_id'] == '66b2cdb625b0afb7ede0022c':\n",
    "    capitulos_novela = pd.DataFrame([{'_id': str(x['_id']),'nombre': x['nombre'], 'url': x['url']} for x in coleccion_app_capitulo.find({'novela_id':row['_id']}, {'_id': 1, 'nombre':1, 'url': 1}).sort('created_at', 1)])\n",
    "    contenidocapitulos_novela = set([str(x['capitulo_id']) for x in coleccion_app_contenidocapitulo.find({'novela_id':row['_id']}, {'_id': 1, 'capitulo_id':1})])\n",
    "    # driver.get(row['url'])\n",
    "    print(f\"Novela {row['nombre']} id: {row['_id']}\")\n",
    "    for idx2, cap in capitulos_novela.iterrows():\n",
    "        if cap['_id'] not in contenidocapitulos_novela:\n",
    "            driver.get(cap['url'])\n",
    "            html_novel_cap = driver.page_source\n",
    "            soup_novel_cap = bs(html_novel_cap, 'html.parser')\n",
    "            content = soup_novel_cap.find('div', class_='reading-content')\n",
    "            content_p = content.find_all('p')\n",
    "            texto_capitulo = ''\n",
    "            for p in content_p:\n",
    "                if len(p.getText()) > 4000:\n",
    "                    texto_traducido = '. '.join([traducir(x) for x in p.getText().strip().rstrip().split('. ') if x != ''])\n",
    "                    texto_capitulo += f\"<p>{texto_traducido}</p>\"\n",
    "                else:\n",
    "                    texto_traducido = traducir(p.getText())\n",
    "                    texto_capitulo += f\"<p>{texto_traducido}</p>\"\n",
    "                \n",
    "            _id = enviar_contenido_capitulo(novel_id=row['_id'], capitulo_id=cap['_id'], texto_capitulo=texto_capitulo)\n",
    "            # print(f\"Capitulo {cap['nombre']} insertado con la ID: {_id}\")\n",
    "            # print(content_p)\n",
    "        # else:\n",
    "        #     print(f\"Capitulo {cap['nombre']} ya se encuentra en la base de datos con la ID: {cap['_id']}\")\n",
    "    # break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
